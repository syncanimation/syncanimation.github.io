# SyncAnimation: A Real-Time End-to-End Framework for Audio-Driven Human Pose and Talking Head Animation 

[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)  
[Project Page]([https://ziqiaopeng.github.io/synctalk/](https://syncanimation.github.io/)) | [Paper (arXiv)](https://arxiv.org/abs/2501.14646) | [Demo Video](https://syncanimation.github.io/)  

> â€œGenerating talking avatar driven by audio remains a significant challenge. Existing methods typically require high computational costs and often lack sufficient facial detail and realism, making them unsuitable for applications that demand high real-time performance and visual quality. Additionally, while some methods can synchronize lip movement, they still face issues with consistency between facial expressions and upper body movement, particularly during silent periods. In this paper, we introduce SyncAnimation, the first NeRF-based method that achieves audio-driven, stable, and real-time generation of speaking avatar by combining generalized audio-to-pose matching and audio-to-expression synchronization. By integrating AudioPose Syncer and AudioEmotion Syncer, SyncAnimation achieves high-precision poses and expression generation, progressively producing audio-synchronized upper body, head, and lip shapes. Furthermore, the High-Synchronization Human Renderer ensures seamless integration of the head and upper body, and achieves audio-sync lip.â€  


## ğŸ§  ç®€ä»‹  

è¯­éŸ³é©±åŠ¨çš„äººè„¸åˆæˆåœ¨å§¿æ€ã€åŒæ­¥æ€§ã€ç»†èŠ‚è¿˜åŸç­‰æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚**SyncTalk** çš„æ ¸å¿ƒåœ¨äº**åŒæ­¥æ€§**ï¼ˆlip sync + è¡¨æƒ… + å¤´éƒ¨è¿åŠ¨ä¸€è‡´æ€§ï¼‰æ§åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼ŒSyncTalk é‡‡ç”¨ä»¥ä¸‹æœºåˆ¶ï¼š

- åŸºäºä¸‰å¹³é¢å“ˆå¸Œ (tri-plane hash) è¡¨ç¤ºæ¥ä¿æŒèº«ä»½ä¸€è‡´æ€§  
- åŒæ—¶ç”ŸæˆåŒæ­¥å£å‹ã€é¢éƒ¨è¡¨æƒ…å’Œç¨³å®šå¤´éƒ¨å§¿æ€  
- åœ¨é«˜åˆ†è¾¨ç‡è§†é¢‘ä¸­æ¢å¤å¤´å‘ç­‰ç»†èŠ‚  

æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªè½»é‡å¿«é€Ÿç‰ˆæœ¬ **SyncTalk_2D**ï¼Œåœ¨é€Ÿåº¦ä¸è´¨é‡ä¹‹é—´å–å¾—æŠ˜ä¸­ã€‚


## ğŸ›  å®‰è£…ä¸ä¾èµ–  

### Linux / Ubuntu  

ä»¥ä¸‹ä¸ºåœ¨ Ubuntu ä¸Šçš„æ¨èå®‰è£…æµç¨‹ï¼ˆå·²çŸ¥åœ¨ Ubuntu 18.04 + PyTorch 1.12.1 + CUDA 11.3 ä¸‹è¿›è¡Œæµ‹è¯•ï¼‰ï¼š

```bash
git clone https://github.com/ZiqiaoPeng/SyncTalk.git
cd SyncTalk

# å»ºè®®ä½¿ç”¨ conda ç¯å¢ƒ
conda create -n synctalk python==3.8.8
conda activate synctalk

# å®‰è£… PyTorch ä¸ torchvisionï¼ˆæ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©å¯¹åº”ç‰ˆæœ¬ï¼‰
pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113

sudo apt-get install portaudio19-dev
pip install -r requirements.txt

# å®‰è£…ä¾èµ–æ¨¡å—ï¼ˆfreqencoder / gridencoder / shencoder / raymarchingï¼‰
pip install ./freqencoder
pip install ./shencoder
pip install ./gridencoder
pip install ./raymarching

# å®‰è£… PyTorch3Dï¼ˆè‹¥æœ‰å›°éš¾ï¼Œå¯ä½¿ç”¨è„šæœ¬ fallback æ–¹æ¡ˆï¼‰
pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu113_pyt1121/download.html
# æˆ–è€…ï¼š
python ./scripts/install_pytorch3d.py

# å®‰è£… TensorFlow GPU ç‰ˆæœ¬ï¼ˆéƒ¨åˆ†æ¨¡å—å¯èƒ½ä¾èµ–ï¼‰
pip install tensorflow-gpu==2.8.1
```

> **æç¤º**ï¼šå®‰è£… PyTorch3D æ—¶å¯èƒ½é‡åˆ°å…¼å®¹æ€§é—®é¢˜ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨ `scripts/install_pytorch3d.py` å¤„ç†ã€‚

---

## ğŸ”„ æ•°æ®å‡†å¤‡  

### é¢„è®­ç»ƒæ¨¡å‹  

è¯·å°†ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä¾‹å¦‚ `May.zip`ã€`trial_may.zip`ï¼‰æ”¾å…¥ç›¸åº”ç›®å½•ï¼š

- `data/May.zip` â†’ è§£å‹è‡³ `data/May/`  
- `model/trial_may.zip` â†’ è§£å‹è‡³ `model/trial_may/`  

### è¾“å…¥è§†é¢‘å¤„ç†  

1. ä¸‹è½½ face-parsing æ¨¡å‹  
   ```bash
   wget https://github.com/YudongGuo/AD-NeRF/blob/master/data_util/face_parsing/79999_iter.pth?raw=true -O data_utils/face_parsing/79999_iter.pth
   ```
2. ä¸‹è½½ 3DMM å¤´å§¿ä¼°è®¡æ¨¡å‹  
   ```bash
   wget â€¦  # å¤šä¸ªæ–‡ä»¶ï¼šexp_info.npy, keys_info.npy, sub_mesh.obj, topology_info.npy  
   ```
3. ä¸‹è½½ Basel Face Model (BFM 2009)ï¼Œè½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼  
   ```bash
   # ä¸‹è½½ .mat æ¨¡å‹æ–‡ä»¶ï¼Œå¹¶æ”¾åˆ° data_utils/face_tracking/3DMM/
   cd data_utils/face_tracking
   python convert_BFM.py
   ```
4. è¾“å…¥è§†é¢‘è¦æ±‚ï¼š  
   - å¸§ç‡ 25 FPS  
   - æ¯å¸§åŒ…å«è®²è¯äººé¢éƒ¨  
   - åˆ†è¾¨ç‡æ¨è ~512Ã—512  
   - æ—¶é•¿çº¦ 4â€“5 åˆ†é’Ÿ  

5. æ‰§è¡Œè§†é¢‘å¤„ç†è„šæœ¬  
   ```bash
   python data_utils/process.py data/<ID>/<ID>.mp4 --asr ave
   ```
   - æ”¯æŒ `ave`ã€`deepspeech`ã€`hubert` ä¸‰ç§ç‰¹å¾æå–  
   - å¯é€‰åœ°ï¼Œè¿è¡Œ OpenFace çš„ `FeatureExtraction`ï¼Œç”Ÿæˆçœ¼ç›çœ¨åŠ¨ AU45 ä¿¡æ¯ï¼ˆé‡å‘½åä¸º `data/<ID>/au.csv`ï¼‰  

> æ³¨æ„ï¼šç”±äº EmoTalk çš„ blendshape æ•æ‰æœªå¼€æºï¼Œå› æ­¤è¿™é‡Œé»˜è®¤ä½¿ç”¨ mediapipe çš„ blendshape æ•æ‰ã€‚å¯¹äºæŸäº›åœºæ™¯æ•ˆæœä¸ä½³ï¼Œå¯è€ƒè™‘æ›¿æ¢æˆ–æ”¹è¿›ã€‚  

---

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹  

### è¯„ä¼° / æ¨ç†  

```bash
python main.py data/May --workspace model/trial_may -O --test --asr_model ave
python main.py data/May --workspace model/trial_may -O --test --asr_model ave --portrait
```

- `--portrait`ï¼šå°†ç”Ÿæˆçš„äººè„¸è´´å›åŸå§‹å›¾åƒ â†’ ç”»è´¨è¾ƒå¥½  
- æˆåŠŸè¿è¡Œåå°†è¾“å‡º PSNR / LPIPS / LMD ç­‰æŒ‡æ ‡  

è‹¥è¦ä½¿ç”¨ç›®æ ‡éŸ³é¢‘è¿›è¡Œæ¨ç†ï¼š

```bash
python main.py data/May --workspace model/trial_may -O --test --test_train --asr_model ave --portrait --aud ./demo/test.wav
```

æ³¨æ„ï¼šéŸ³é¢‘éœ€ä¸º `.wav` æ ¼å¼ã€‚å¦‚æœä½¿ç”¨å…¶ä»–ç‰¹å¾ï¼ˆå¦‚ npyï¼‰ï¼Œå¯æ”¹è·¯å¾„è‡³å¯¹åº”æ–‡ä»¶ã€‚

### è®­ç»ƒ  

é»˜è®¤æ–¹å¼ä»ç£ç›˜æŒ‰éœ€åŠ è½½æ•°æ®ï¼š

```bash
python main.py data/May --workspace model/trial_may -O --iters 60000 --asr_model ave
python main.py data/May --workspace model/trial_may -O --iters 100000 --finetune_lips --patch_size 64 --asr_model ave
# æˆ–è€…ä½¿ç”¨è„šæœ¬
sh ./scripts/train_may.sh
```

è‹¥æƒ³åŠ å…¥èº¯å¹²è®­ç»ƒä»¥ä¿®å¤åŒä¸‹å·´ï¼ˆæ³¨æ„ï¼šè®­ç»ƒèº¯å¹²åä¸èƒ½ç”¨ `--portrait` æ¨¡å¼ï¼‰ï¼š

```bash
python main.py data/May/ --workspace model/trial_may_torso/ -O --torso --head_ckpt <head_ckpt>.pth --iters 150000 --asr_model ave
python main.py data/May --workspace model/trial_may_torso -O --torso --test --asr_model ave
python main.py data/May --workspace model/trial_may_torso -O --torso --test --test_train --asr_model ave --aud ./demo/test.wav
```

---

## ğŸ“Š è¯„ä»·æŒ‡æ ‡  

ç¤ºä¾‹ï¼ˆå•äººï¼‰ï¼š

| æ¨¡å¼                      | PSNR    | LPIPS    | LMD     |
|---------------------------|---------|-----------|---------|
| SyncTalk (ä¸è´´å›åŸå›¾)     | 32.201  | 0.0394    | 2.822   |
| SyncTalk (è´´å›åŸå›¾)       | 37.644  | 0.0117    | 2.825   |

ï¼ˆè®ºæ–‡ç»™å‡ºäº†å¤šä¸ªè¢«è¯•çš„å¹³å‡æŒ‡æ ‡ï¼‰

---

## ğŸ“ å¼•ç”¨  

è¯·åœ¨ä½¿ç”¨æœ¬æ–¹æ³•ã€æ¨¡å‹æˆ–åŸºäºæœ¬é¡¹ç›®è¡ç”Ÿç ”ç©¶æ—¶å¼•ç”¨ä»¥ä¸‹æ–‡çŒ®ï¼š

```tex
@inproceedings{peng2024synctalk,
  title     = {SyncTalk: The devil is in the synchronization for talking head synthesis},
  author    = {Peng, Ziqiao and Hu, Wentao and Shi, Yue and Zhu, Xiangyu and Zhang, Xiaomei and Zhao, Hao and He, Jun and Liu, Hongyan and Fan, Zhaoxin},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {666--676},
  year      = {2024}
}
```

---

## ğŸ™ è‡´è°¢  

æœ¬é¡¹ç›®åœ¨å®ç°è¿‡ç¨‹ä¸­ä¾èµ–æˆ–å€Ÿé‰´äº†ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š

- ER-NeRF  
- RAD-NeRF  
- GeneFace  
- DFRF  
- DFA-NeRF  
- AD-NeRF  
- Deep3DFaceRecon_pytorch  

æ„Ÿè°¢ä¸Šè¿°é¡¹ç›®ä½œè€…çš„å¼€æ”¾ç¤¾åŒºè´¡çŒ®ï¼Œä¹Ÿæ„Ÿè°¢è¯¸å¤šåŒå­¦åœ¨ bug ä¿®å¤ã€åŠŸèƒ½è®¾è®¡ã€æ•°æ®é¢„å¤„ç†ç­‰æ–¹é¢çš„å¸®åŠ©ï¼ˆå¦‚ Tiandishihua åŒå­¦ä¿®å¤ NaN é—®é¢˜ï¼‰ã€‚  

---

## âš ï¸ å…è´£å£°æ˜  

ä½¿ç”¨æœ¬é¡¹ç›®å³è¡¨ç¤ºä½ åŒæ„éµå®ˆæ‰€æœ‰ç›¸å…³æ³•å¾‹æ³•è§„ï¼Œä¸å¾—å°†å…¶ç”¨äºç”Ÿæˆæˆ–ä¼ æ’­æœ‰å®³å†…å®¹ã€‚å¼€å‘è€…å¯¹äºå› ä½¿ç”¨æˆ–æ»¥ç”¨è¯¥è½¯ä»¶æ‰€å¯¼è‡´çš„ä»»ä½•ç›´æ¥ã€é—´æ¥æˆ–è¡ç”ŸæŸå¤±ä¸æ‰¿æ‹…è´£ä»»ã€‚  
