<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
<!--   <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF"> -->
<!--   <meta name="viewport" content="width=device-width, initial-scale=1"> -->
<!--   <title>Audiodynamic: Real-Time Audio-Driven Talking Head and Torso Generation with Disentangled Head Pose and Expressions</title> -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SyncAnimation: A Real-Time End-to-End Framework for Audio-Driven Human Pose and Talking Head Animation</h1>
<!--           <div class="is-size-5 publication-authors">
            <span class="author-block">
              Yujian Liu<sup>1,2</sup>,</span>
            <span class="author-block">
              Shidang Xu<sup>2</sup>,</span>
            <span class="author-block">
              Jing Guo<sup>1,3</sup>,
            </span>
            <span class="author-block">
              Zairan Wang<sup>1</sup>,
            </span>
            <span class="author-block">
              Xiaoli Liu<sup>1</sup>,
            </span>
          </div> -->

<!--           <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>AiShiWeiLai AI Research, Beijing, China,</span>
            <span class="author-block"><sup>2</sup>South China University of Technology, Guangzhou, China</span>
            <span class="author-block"><sup>3</sup>Beijing Institute of Technology, Beijing, China</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
<!--               <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
<!--               <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Code Link. -->
<!--               <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
<!--               <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="abstract">
  <div class="container is-max-desktop">
    <div class="abstract">
      <h1 class="title is-3" style="font-size: 2.1em; font-weight: bold; margin-bottom: 20px; text-align: center;">Abstract</h1>
      <div style="text-align: justify">
        <p>Generating talking avatars driven by audio remains a significant challenge. Existing methods typically require high computational costs and often lack sufficient facial detail and realism, making them unsuitable for applications that demand high real-time performance and visual quality. Additionally, while some methods can synchronize lip movement, they still face issues with consistency between facial expressions and upper body movement, particularly during silent periods.</p>
        
        <p>In this paper, we introduce SyncAnimation, the first NeRF-based method that achieves audio-driven, stable, and real-time generation of speaking avatars by combining generalized audio-to-pose matching and audio-to-expression synchronization. By integrating AudioPose Syncer and AudioEmotion Syncer, SyncAnimation achieves high-precision poses and expression generation, progressively producing audio-synchronized upper body, head, and lip shapes. Furthermore, the High-Synchronization Human Renderer ensures seamless integration of the head and upper body, and achieves audio-sync lip movements.</p>
      </div>
    </div>
  </div>
</section>
  
<section class="Audiodynamic">
  <div class="container is-max-desktop">
    <div class="Audiodynamic-body">

      <img src="./static/images/figure1.png" alt="Audiodynamic Image" style="width: 100%; margin-top: 10px; height: auto;">
      <h2 class="text-align: justify" style="width: 100%; text-align: justify; margin-top: 5px;"> 
        SyncAnimation is the first NeRF-based fully generative approach that utilizes audio-driven generation to create expressions and an adjustable torso (left). 
        SyncAnimation requires only audio and monocular, or even noise, to render highly detailed identity information, along with realistic and dynamic facial and torso changes, while maintaining audio consistency (right).
      </h2>
    </div>
  </div>
</section>

<section class="Overall_Pipeline">
  <div class="container is-max-desktop">
    <div class="Overall_Pipeline">
      <h1 class="title is-3" style="font-size: 2.1em; font-weight: bold; margin-bottom: 20px; margin-top: 30px; text-align: center;">Overall Pipeline</h1>
      <img src="./static/images/pipline.png" alt="Audiodynamic Image" style="width: 100%; height: auto;">
      <h2 class="text-align: justify" style="width: 100%; text-align: justify; margin-top: 3px; margin-bottom: 20px;"> 
        SyncAnimation Framework: Given an image and audio, the preprocessing extracts 3DMM parameters for Audio2Pose and Audio2Emotion as references (or noise). 
        It then generates the upper body, head, and lip refinement, ensuring pose consistency and facial expression alignment with the audio.
      </h2>
    </div>
  </div>
</section>



<section class="hero teaser" style="box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); padding: 20px; border-radius: 8px; width: 70%; margin: 0 auto;margin-bottom: 30px;">
  <div class="container is-max-desktop" style="padding: 0; margin: 0;">
    <div class="hero-body">
      <!-- h2 居中对齐 -->
      <h2 class="title is-3" style="font-size: 2.1em; font-weight: bold; margin-bottom: 20px; text-align: center;">Comparison with SOTA</h2>

      <!-- h3 左对齐，并且去除左右内边距 -->
      <h3 class="title is-4" style="text-align: left; margin: 0; padding: 20px 0px;">Comparison with Gan</h3>
        <!-- We compare with 四个 one-shot methods在: Wav2Lip, DINet (CVPR 2023),IP-LAP and EDTalk. 我们的SyncAnimation实现了动态且清晰的唇型，以及唇音一致性
          --> 
        <h4 class="text-align: justify" style="width: 100%; text-align: justify; margin-top: 5px; margin-bottom: 5px;">
          We compare with four one-shot methods: <a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413532" target="_blank">Wav2Lip</a> (ACM MM 2020), 
          <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25464" target="_blank">DINet</a> (AAAI 2023), 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zhong_Identity-Preserving_Talking_Face_Generation_With_Landmark_and_Appearance_Priors_CVPR_2023_paper.html">IP-LAP</a> (CVPR 2023), 
          and <a href="https://link.springer.com/chapter/10.1007/978-3-031-72658-3_23" target="_blank">EDTalk</a> (ECCV 2024). Our SyncAnimation achieves dynamic and clear lip shapes, as well as lip-audio consistency.  
        </h4>
      
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/May_gan_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/RonWyden1_gan_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/DebFischer0_gan_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/ChrisMurphy1_gan_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
      
      <h3 class="title is-4" style="text-align: left; margin: 0; padding: 20px 0px;">Comparison with Nerf</h3>
          <!-- We compare with 三个 one-shot methods在: ER-NeRF, SyncTalk (CVPR 2023) and GeneFace++ 。我们的SyncAnimation实现了具有强语音相关性的avatar姿势和表情
          --> 
        <h4 class="text-align: justify" style="width: 100%; text-align: justify; margin-top: 5px; margin-bottom: 5px;">
          We compare with three one-shot methods: <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.html?ref=https://githubhelp.com" target="_blank">ER-NeRF</a> (ICCV 2023), 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Peng_SyncTalk_The_Devil_is_in_the_Synchronization_for_Talking_Head_CVPR_2024_paper.html" target="_blank">SyncTalk</a> (CVPR 2024),  
          and <a href="https://arxiv.org/abs/2305.00787" target="_blank">GeneFace++</a> (arXiv 2023). SyncAnimation is the only method that successfully achieves avatar poses and expressions with strong audio correlation.
        </h4>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/May_nerf_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/RonWyden1_nerf_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/DebFischer0_nerf_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/ChrisMurphy1_nerf_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
      
      <h3 class="title is-4" style="text-align: left; margin: 0; padding: 20px 0px;">Comparison with Stable Diffusion</h3>
        <!-- We compare with 三个 one-shot methods: Hallo, V-Express (CVPR 2023) and EchoMimic 。我们的SyncAnimation实现逼真的avatar，
             拥有更多的面部细节，和更丰富的姿势和表情
          --> 
        <h4 class="text-align: justify" style="width: 100%; text-align: justify; margin-top: 5px; margin-bottom: 5px;">
          We compare with three one-shot methods: <a href="https://arxiv.org/abs/2406.08801" target="_blank">Hallo</a> (arXiv 2024), 
          <a href="https://arxiv.org/abs/2406.02511" target="_blank">V-Express</a> (arXiv 2024),  
          and <a href="https://arxiv.org/abs/2407.08136" target="_blank">EchoMimic</a> (arxiv 2024). Our SyncAnimation generates realistic avatars with more facial details and richer poses and expressions.
        </h4>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/May_sd_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/RonWyden1_sd_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/DebFischer0_sd_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
        <video id="teaser" controls playsinline height="100%">
          <source src="./static/videos/ChrisMurphy1_sd_vs_ours_with_bottom_border_and_title.mp4" type="video/mp4">
        </video>
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser" style="box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); padding: 20px; border-radius: 8px; width: 70%; margin: 0 auto;margin-bottom: 30px;">
  <div class="container is-max-desktop" style="padding: 0; margin: 0;">
    <div class="hero-body">
      <!-- h2 居中对齐 -->
      <h2 class="title is-3" style="font-size: 2.1em; font-weight: bold; margin-bottom: 20px; text-align: center;">Torso Scaling Expansion</h2>
      <div style="display: flex; justify-content: space-between; gap: 5px; max-width: 100%; margin: 0 auto; box-sizing: border-box;">
          <video id="teaser1" controls playsinline style="height: 50%; width: 48%; max-width: 48%;">
            <source src="./static/videos/3-DebFischer0+May.mp4" type="video/mp4">
          </video>
          <video id="teaser2" controls playsinline style="height: 50%; width: 48%; max-width: 48%;">
            <source src="./static/videos/4-DebFischer0+May.mp4" type="video/mp4">
          </video>
        </div>
      <div style="display: flex; justify-content: space-between; gap: 5px; max-width: 100%; margin-top: 20px;; box-sizing: border-box;">
          <video id="teaser1" controls playsinline style="height: 50%; width: 48%; max-width: 48%;">
            <source src="./static/videos/1-ChrisVanHollen1+RonWyden1.mp4" type="video/mp4">
          </video>
          <video id="teaser2" controls playsinline style="height: 50%; width: 48%; max-width: 48%;">
            <source src="./static/videos/2-ChrisVanHollen1+RonWyden1.mp4" type="video/mp4">
          </video>
        </div>
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser" style="box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); padding: 20px; border-radius: 8px; width: 70%; margin: 0 auto;margin-bottom: 30px;">
  <div class="container is-max-desktop" style="padding: 0; margin: 0;">
    <div class="hero-body">
      <!-- h2 居中对齐 -->
      <h2 class="title is-3" style="font-size: 2.1em; font-weight: bold; margin-bottom: 20px; text-align: center;">Live News</h2>
        <div style="display: flex; justify-content: space-between; gap: 10px; max-width: 100%; margin: 0 auto; box-sizing: border-box;">
          <video id="teaser1" controls playsinline style="height: 50%; width: 48%; max-width: 48%;">
            <source src="./static/videos/5-DebFischer0+RonWyden1-com.mp4" type="video/mp4">
          </video>
          <video id="teaser2" controls playsinline style="height: 50%; width: 48%; max-width: 48%;">
            <source src="./static/videos/6-May+ChrisVanHollen1-com.mp4" type="video/mp4">
          </video>
        </div>
      </h2>
    </div>
  </div>
</section>


  
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3" style="text-align: center;">Comparison with SOTA</h2>
<!--       <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <h2 class="subtitle has-text-centered">
<!--         portraits. -->
      </h2>
    </div>
  </div>
</section> -->

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3" style="text-align: center;">Torso Scaling Expansion</h2>
<!--       <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <h2 class="subtitle has-text-centered">
<!--         portraits. -->
      </h2>
    </div>
  </div>
</section> -->
  
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3" style="text-align: center;">Live News</h2>
<!--       <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <h2 class="subtitle has-text-centered">
<!--         portraits. -->
      </h2>
    </div>
  </div>
</section> -->

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
  </div>
</footer>

</body>
</html>
